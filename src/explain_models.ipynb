{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from captum.attr import IntegratedGradients, Saliency, GradientShap, Occlusion\n",
    "from captum.attr import visualization as viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC_DIR = Path.cwd()\n",
    "ROOT_DIR = SRC_DIR.parent\n",
    "\n",
    "DATA_DIR = os.path.join(ROOT_DIR, 'dataset')\n",
    "PREPROCESSED_DIR = os.path.join(DATA_DIR, 'preprocessed')\n",
    "CSV_PATH = os.path.join(DATA_DIR, 'csv_mappings', 'train.csv')\n",
    "\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, 'models')\n",
    "BASELINE_DIR = os.path.join(MODEL_DIR, 'baselines_finetuned')\n",
    "RESULT_DIR = os.path.join(BASELINE_DIR, 'results')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASS_NAMES = {\n",
    "    0: \"amanita\",\n",
    "    1: \"boletus\",\n",
    "    2: \"chantelle\",\n",
    "    3: \"deterrimus\",\n",
    "    4: \"rufus\",\n",
    "    5: \"torminosus\",\n",
    "    6: \"aurantiacum\",\n",
    "    7: \"procera\",\n",
    "    8: \"involutus\",\n",
    "    9: \"russula\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader, test_loader = training.get_data_loaders(PREPROCESSED_DIR, CSV_PATH, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "NUM_CLASSES = 10 \n",
    "EPOCHS = 20\n",
    "PATIENCE = 3\n",
    "LEARNING_RATE = 0.0001\n",
    "\n",
    "SCHEDULER = 'StepLR' # StepLR # OneCycleLR # None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load model to explain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = 'alexnet'  \n",
    "\n",
    "# alexnet # resnet # vgg16 # densenet # efficientnet\n",
    "# custom_alexnet custom_resnet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = training.load_model_for_explaining(model_type, NUM_CLASSES, DEVICE, finetuned=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Explain model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explain_with_integrated_gradients(model, input_tensor, target_class, device):\n",
    "    model.eval()\n",
    "    input_tensor = input_tensor.to(device)\n",
    "    \n",
    "    ig = IntegratedGradients(model)\n",
    "    attributions, _ = ig.attribute(input_tensor, target=target_class, return_convergence_delta=True)\n",
    "    return attributions.cpu().detach().numpy()\n",
    "\n",
    "\n",
    "def explain_with_saliency(model, input_tensor, target_class, device):\n",
    "    model.eval()\n",
    "    input_tensor = input_tensor.to(device)\n",
    "    \n",
    "    saliency = Saliency(model)\n",
    "    attributions = saliency.attribute(input_tensor, target=target_class)\n",
    "    return attributions.cpu().detach().numpy()\n",
    "\n",
    "\n",
    "def explain_with_gradient_shap(model, input_tensor, target_class, device):\n",
    "    model.eval()\n",
    "    input_tensor = input_tensor.to(device)\n",
    "    \n",
    "    baseline = torch.zeros_like(input_tensor).to(device)\n",
    "    gradient_shap = GradientShap(model)\n",
    "    attributions = gradient_shap.attribute(input_tensor, baselines=baseline, target=target_class)\n",
    "    return attributions.cpu().detach().numpy()\n",
    "\n",
    "\n",
    "def explain_with_occlusion(model, input_tensor, target_class, device):\n",
    "    model.eval()\n",
    "    input_tensor = input_tensor.to(device)\n",
    "    \n",
    "    occlusion = Occlusion(model)\n",
    "    sliding_window_shape = (input_tensor.shape[1], 15, 15)  \n",
    "    attributions = occlusion.attribute(input_tensor, target=target_class, sliding_window_shapes=sliding_window_shape)\n",
    "    return attributions.cpu().detach().numpy()\n",
    "\n",
    "\n",
    "def visualize_attributions(attributions, original_image, class_name):\n",
    "    attributions = np.transpose(attributions[0], (1, 2, 0))\n",
    "    original_image = np.transpose(original_image[0], (1, 2, 0))\n",
    "    _ = viz.visualize_image_attr(attributions, original_image, method=\"blended_heat_map\", sign=\"positive\",\n",
    "                                 show_colorbar=True, title=f\"Explanation for class: {class_name}\")\n",
    "\n",
    "\n",
    "def generate_explanations(model, input_tensor, target_class, class_names, device):\n",
    "    original_image = input_tensor.cpu().detach().numpy()\n",
    "    target_class_name = class_names[target_class]\n",
    "\n",
    "    ig_attr = explain_with_integrated_gradients(model, input_tensor, target_class, device)\n",
    "    saliency_attr = explain_with_saliency(model, input_tensor, target_class, device)\n",
    "    gradient_shap_attr = explain_with_gradient_shap(model, input_tensor, target_class, device)\n",
    "    occlusion_attr = explain_with_occlusion(model, input_tensor, target_class, device)\n",
    "\n",
    "    plt.figure(figsize=(20, 10))\n",
    "\n",
    "    plt.subplot(2, 2, 1)\n",
    "    visualize_attributions(ig_attr, original_image, f\"IG: {target_class_name}\")\n",
    "\n",
    "    plt.subplot(2, 2, 2)\n",
    "    visualize_attributions(saliency_attr, original_image, f\"Saliency: {target_class_name}\")\n",
    "\n",
    "    plt.subplot(2, 2, 3)\n",
    "    visualize_attributions(gradient_shap_attr, original_image, f\"Gradient SHAP: {target_class_name}\")\n",
    "\n",
    "    plt.subplot(2, 2, 4)\n",
    "    visualize_attributions(occlusion_attr, original_image, f\"Occlusion: {target_class_name}\")\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in test_loader:\n",
    "    inputs, labels = batch \n",
    "    input_tensor = inputs[0].unsqueeze(0)  \n",
    "    target_class = labels[0].item() \n",
    "    break  \n",
    "\n",
    "generate_explanations(model, input_tensor, target_class, CLASS_NAMES, DEVICE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
