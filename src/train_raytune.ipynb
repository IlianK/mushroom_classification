{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ilian\\Documents\\Projects\\git_projects\\university\\mushroom_classification\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-01-09 21:45:33,875\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "2025-01-09 21:45:36,673\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR, OneCycleLR\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import seaborn as sns\n",
    "from ray import tune\n",
    "from torchvision import models\n",
    "import numpy as np\n",
    "from torch.utils.tensorboard import SummaryWriter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x269116dc830>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_folder = Path.cwd()\n",
    "root_folder = src_folder.parent\n",
    "dataset_folder = os.path.join(root_folder, 'dataset')\n",
    "models_folder = os.path.join(root_folder, 'models')\n",
    "\n",
    "baseline_folder = os.path.join(models_folder, 'baselines')\n",
    "result_folder = os.path.join(baseline_folder, 'results')\n",
    "\n",
    "PREPROCESSED_DIR = os.path.join(dataset_folder, 'preprocessed')\n",
    "CSV_PATH = os.path.join(dataset_folder, 'csv_mappings', 'train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "NUM_CLASSES = 10 \n",
    "EPOCHS = 20\n",
    "PATIENCE = 3\n",
    "LEARNING_RATE = 0.0001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preperation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mushroom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MushroomDataset(Dataset):\n",
    "    def __init__(self, preprocessed_dir, csv_path, transform=None):\n",
    "        self.preprocessed_dir = preprocessed_dir  \n",
    "        self.csv_path = csv_path  \n",
    "        self.transform = transform  \n",
    "        self.csv_data = pd.read_csv(csv_path)\n",
    "        \n",
    "        # Images and Labels\n",
    "        self.image_ids = self.csv_data['Image'].values  \n",
    "        self.labels = self.csv_data['Mushroom'].values \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_ids)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image_id = self.image_ids[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        image_id_str = str(image_id).zfill(5)  # Pad for filename\n",
    "        \n",
    "        # Load .pt files\n",
    "        image_path = os.path.join(self.preprocessed_dir, f\"{image_id_str}.pt\")\n",
    "        image = torch.load(image_path)  \n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MushroomDataset(PREPROCESSED_DIR, CSV_PATH)\n",
    "indices = list(range(len(dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices, temp_indices = train_test_split(indices, test_size=0.3, random_state=42)\n",
    "val_indices, test_indices = train_test_split(temp_indices, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_subset = torch.utils.data.Subset(dataset, train_indices)\n",
    "val_subset = torch.utils.data.Subset(dataset, val_indices)\n",
    "test_subset = torch.utils.data.Subset(dataset, test_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_subset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_subset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_subset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train & Test functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, optimizer, epoch, loss, accuracy, file_path):\n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': loss,\n",
    "        'accuracy': accuracy,\n",
    "    }\n",
    "\n",
    "    torch.save(checkpoint, file_path)\n",
    "    print(f\"Model saved to {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_on_epoch(model, train_loader, criterion, optimizer, device, epoch, writer, scheduler):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for batch_idx, data in enumerate(tqdm(train_loader, desc=\"[Train]\")):\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    train_accuracy = 100.0 * correct / total\n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "\n",
    "    for param_group in optimizer.param_groups:\n",
    "        writer.add_scalar('Train/Learning Rate', param_group['lr'], epoch)\n",
    "\n",
    "    if scheduler:\n",
    "        scheduler.step()\n",
    "\n",
    "    writer.add_scalar('Train/Loss', avg_train_loss, epoch)\n",
    "    writer.add_scalar('Train/Accuracy', train_accuracy, epoch)\n",
    "\n",
    "    return avg_train_loss, train_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_on_epoch(model, val_loader, criterion, optimizer, device, epoch, writer, best_val_loss, patience, epochs_no_improve, save_path):\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, data in enumerate(tqdm(val_loader, desc=\"[Val]\")):\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    val_accuracy = 100.0 * correct / total\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "\n",
    "    writer.add_scalar('Validation/Loss', avg_val_loss, epoch)\n",
    "    writer.add_scalar('Validation/Accuracy', val_accuracy, epoch)\n",
    "\n",
    "    # Early stopping \n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        save_model(model, optimizer, epoch, avg_val_loss, val_accuracy, save_path)\n",
    "\n",
    "    return avg_val_loss, val_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader, criterion, device):\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_labels = []\n",
    "    all_predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(test_loader, desc=\"[Test]\"):\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "            # Store preds and labels for plots\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "    test_accuracy = 100.0 * correct / total\n",
    "    avg_test_loss = test_loss / len(test_loader)\n",
    "\n",
    "    print(f\"Test Loss = {avg_test_loss:.4f}\")\n",
    "    print(f\"Test Accuracy = {test_accuracy:.2f}%\")\n",
    "    \n",
    "    return avg_test_loss, test_accuracy, all_labels, all_predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(all_labels, all_predictions, num_classes, save_path=None):\n",
    "    conf_matrix = confusion_matrix(all_labels, all_predictions, labels=np.arange(num_classes))\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", \n",
    "                xticklabels=np.arange(num_classes), yticklabels=np.arange(num_classes))\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "\n",
    "    if save_path:\n",
    "        os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "        plt.savefig(save_path)\n",
    "        print(f\"Confusion matrix saved to {save_path}\")\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def per_class_accuracy(all_labels, all_predictions, num_classes):\n",
    "    class_accuracies = []\n",
    "    \n",
    "    for i in range(num_classes):\n",
    "        class_indices = [j for j, label in enumerate(all_labels) if label == i]\n",
    "        class_predictions = [all_predictions[j] for j in class_indices]\n",
    "        class_labels = [all_labels[j] for j in class_indices]\n",
    "        \n",
    "        class_accuracy = accuracy_score(class_labels, class_predictions)\n",
    "        class_accuracies.append(class_accuracy)\n",
    "        print(f\"Accuracy class {i}: {class_accuracy:.4f}\")\n",
    "    \n",
    "    return class_accuracies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_classification_report_as_dataframe(all_labels, all_predictions):\n",
    "    report_dict = classification_report(all_labels, all_predictions, target_names=[str(i) for i in range(len(set(all_labels)))], output_dict=True)\n",
    "    report_df = pd.DataFrame(report_dict).transpose()\n",
    "    display(report_df)\n",
    "    return report_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnhancedResNet(nn.Module):\n",
    "    def __init__(self, num_classes=10, dropout_prob=0.5):\n",
    "        super(EnhancedResNet, self).__init__()\n",
    "\n",
    "        self.resnet = models.resnet50(pretrained=True)  \n",
    "        self.resnet.fc = nn.Identity()\n",
    "        self.dropout = nn.Dropout(p=dropout_prob)\n",
    "        \n",
    "        self.fc1 = nn.Linear(2048, 1024)  \n",
    "        self.fc2 = nn.Linear(1024, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.resnet(x)  \n",
    "        x = self.dropout(x) \n",
    "        x = torch.relu(self.fc1(x)) \n",
    "        x = self.fc2(x)  \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "\n",
    "def get_optimizer_and_scheduler(model, lr=0.001, weight_decay=1e-5, momentum=0.9):\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    \n",
    "    # scheduler = StepLR(optimizer, step_size=2, gamma=0.5)\n",
    "    scheduler = OneCycleLR(\n",
    "        optimizer,\n",
    "        max_lr=lr,  \n",
    "        steps_per_epoch=len(train_loader),\n",
    "        epochs=EPOCHS,\n",
    "        pct_start=0.3,\n",
    "        anneal_strategy='cos',\n",
    "        div_factor=25.0,\n",
    "        final_div_factor=10000.0\n",
    "    )\n",
    "    \n",
    "    return optimizer, scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setter for model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_model_for_training(config, model_type, baseline_folder, NUM_CLASSES):\n",
    "    base_log_path = os.path.join(baseline_folder, model_type, 'log')\n",
    "    base_result_path = os.path.join(baseline_folder, model_type, 'results')\n",
    "\n",
    "    if os.path.exists(base_log_path):\n",
    "        shutil.rmtree(base_log_path)\n",
    "    os.makedirs(base_log_path, exist_ok=True)\n",
    "    os.makedirs(base_result_path, exist_ok=True)\n",
    "\n",
    "    dropout_prob = config['dropout_prob']\n",
    "    model = EnhancedResNet(num_classes=NUM_CLASSES, dropout_prob=dropout_prob)\n",
    "\n",
    "    save_path = os.path.join(base_result_path, \"model_custom.pth\")\n",
    "    writer = SummaryWriter(log_dir=base_log_path)\n",
    "\n",
    "    return model, save_path, writer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(config, train_loader, val_loader, device, baseline_folder, NUM_CLASSES, EPOCHS):\n",
    "    model, save_path, writer = set_model_for_training(config, model_type='custom', baseline_folder=baseline_folder, NUM_CLASSES=NUM_CLASSES)\n",
    "    optimizer, scheduler = get_optimizer_and_scheduler(model, config, train_loader, EPOCHS)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    best_val_loss = float('inf')\n",
    "    epochs_no_improve = 0\n",
    "    patience = 5\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        # Train and validate\n",
    "        train_loss, train_accuracy = train_on_epoch(model, train_loader, criterion, optimizer, device, epoch, writer, scheduler)\n",
    "        val_loss, val_accuracy = validate_on_epoch(model, val_loader, criterion, optimizer, device, epoch, writer, best_val_loss, patience, epochs_no_improve, save_path)\n",
    "        \n",
    "        # Report Ray Tune\n",
    "        tune.report(val_loss=val_loss, val_accuracy=val_accuracy)\n",
    "\n",
    "        # Early stopping\n",
    "        if epochs_no_improve >= patience:\n",
    "            break\n",
    "    \n",
    "    return val_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-09 21:51:22,650\tINFO tune.py:616 -- [output] This uses the legacy output and progress reporter, as Jupyter notebooks are not supported by the new engine, yet. For more information, please see https://github.com/ray-project/ray/issues/36949\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2025-01-09 21:56:45</td></tr>\n",
       "<tr><td>Running for: </td><td>00:05:22.97        </td></tr>\n",
       "<tr><td>Memory:      </td><td>27.5/31.4 GiB      </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using AsyncHyperBand: num_stopped=0<br>Bracket: Iter 16.000: None | Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None<br>Logical resource usage: 0/22 CPUs, 0/0 GPUs\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">  dropout_prob</th><th style=\"text-align: right;\">    lr</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_tune_7c0ec_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">0.0001</td></tr>\n",
       "<tr><td>train_tune_7c0ec_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">0.0001</td></tr>\n",
       "<tr><td>train_tune_7c0ec_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           0.7</td><td style=\"text-align: right;\">0.0001</td></tr>\n",
       "<tr><td>train_tune_7c0ec_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">0.001 </td></tr>\n",
       "<tr><td>train_tune_7c0ec_00004</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">0.001 </td></tr>\n",
       "<tr><td>train_tune_7c0ec_00005</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           0.7</td><td style=\"text-align: right;\">0.001 </td></tr>\n",
       "<tr><td>train_tune_7c0ec_00006</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           0.3</td><td style=\"text-align: right;\">0.01  </td></tr>\n",
       "<tr><td>train_tune_7c0ec_00007</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           0.5</td><td style=\"text-align: right;\">0.01  </td></tr>\n",
       "<tr><td>train_tune_7c0ec_00008</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           0.7</td><td style=\"text-align: right;\">0.01  </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-09 21:52:23,150\tWARNING insufficient_resources_manager.py:163 -- Ignore this message if the cluster is autoscaling. No trial is running and no new trial has been started within the last 60 seconds. This could be due to the cluster not having enough resources available. You asked for 1.0 CPUs and 1.0 GPUs per trial, but the cluster only has 22.0 CPUs and 0 GPUs available. Stop the tuning and adjust the required resources (e.g. via the `ScalingConfig` or `resources_per_trial`, or `num_workers` for rllib), or add more resources to your cluster.\n",
      "2025-01-09 21:53:23,226\tWARNING insufficient_resources_manager.py:163 -- Ignore this message if the cluster is autoscaling. No trial is running and no new trial has been started within the last 60 seconds. This could be due to the cluster not having enough resources available. You asked for 1.0 CPUs and 1.0 GPUs per trial, but the cluster only has 22.0 CPUs and 0 GPUs available. Stop the tuning and adjust the required resources (e.g. via the `ScalingConfig` or `resources_per_trial`, or `num_workers` for rllib), or add more resources to your cluster.\n",
      "2025-01-09 21:54:23,329\tWARNING insufficient_resources_manager.py:163 -- Ignore this message if the cluster is autoscaling. No trial is running and no new trial has been started within the last 60 seconds. This could be due to the cluster not having enough resources available. You asked for 1.0 CPUs and 1.0 GPUs per trial, but the cluster only has 22.0 CPUs and 0 GPUs available. Stop the tuning and adjust the required resources (e.g. via the `ScalingConfig` or `resources_per_trial`, or `num_workers` for rllib), or add more resources to your cluster.\n",
      "2025-01-09 21:55:23,379\tWARNING insufficient_resources_manager.py:163 -- Ignore this message if the cluster is autoscaling. No trial is running and no new trial has been started within the last 60 seconds. This could be due to the cluster not having enough resources available. You asked for 1.0 CPUs and 1.0 GPUs per trial, but the cluster only has 22.0 CPUs and 0 GPUs available. Stop the tuning and adjust the required resources (e.g. via the `ScalingConfig` or `resources_per_trial`, or `num_workers` for rllib), or add more resources to your cluster.\n",
      "2025-01-09 21:56:23,450\tWARNING insufficient_resources_manager.py:163 -- Ignore this message if the cluster is autoscaling. No trial is running and no new trial has been started within the last 60 seconds. This could be due to the cluster not having enough resources available. You asked for 1.0 CPUs and 1.0 GPUs per trial, but the cluster only has 22.0 CPUs and 0 GPUs available. Stop the tuning and adjust the required resources (e.g. via the `ScalingConfig` or `resources_per_trial`, or `num_workers` for rllib), or add more resources to your cluster.\n",
      "2025-01-09 21:56:45,632\tWARNING tune.py:219 -- Stop signal received (e.g. via SIGINT/Ctrl+C), ending Ray Tune run. This will try to checkpoint the experiment state one last time. Press CTRL+C (or send SIGINT/SIGKILL/SIGTERM) to skip. \n",
      "2025-01-09 21:56:45,654\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to 'C:/Users/ilian/ray_results/train_tune_2025-01-09_21-51-22' in 0.0193s.\n",
      "2025-01-09 21:56:45,702\tINFO tune.py:1041 -- Total run time: 323.05 seconds (322.94 seconds for the tuning loop).\n",
      "2025-01-09 21:56:45,704\tWARNING tune.py:1056 -- Experiment has been interrupted, but the most recent state was saved.\n",
      "Resume experiment with: tune.run(..., resume=True)\n",
      "2025-01-09 21:56:45,714\tWARNING experiment_analysis.py:180 -- Failed to fetch metrics for 9 trial(s):\n",
      "- train_tune_7c0ec_00000: FileNotFoundError('Could not fetch metrics for train_tune_7c0ec_00000: both result.json and progress.csv were not found at C:/Users/ilian/ray_results/train_tune_2025-01-09_21-51-22/train_tune_7c0ec_00000_0_dropout_prob=0.3000,lr=0.0001_2025-01-09_21-51-22')\n",
      "- train_tune_7c0ec_00001: FileNotFoundError('Could not fetch metrics for train_tune_7c0ec_00001: both result.json and progress.csv were not found at C:/Users/ilian/ray_results/train_tune_2025-01-09_21-51-22/train_tune_7c0ec_00001_1_dropout_prob=0.5000,lr=0.0001_2025-01-09_21-51-22')\n",
      "- train_tune_7c0ec_00002: FileNotFoundError('Could not fetch metrics for train_tune_7c0ec_00002: both result.json and progress.csv were not found at C:/Users/ilian/ray_results/train_tune_2025-01-09_21-51-22/train_tune_7c0ec_00002_2_dropout_prob=0.7000,lr=0.0001_2025-01-09_21-51-22')\n",
      "- train_tune_7c0ec_00003: FileNotFoundError('Could not fetch metrics for train_tune_7c0ec_00003: both result.json and progress.csv were not found at C:/Users/ilian/ray_results/train_tune_2025-01-09_21-51-22/train_tune_7c0ec_00003_3_dropout_prob=0.3000,lr=0.0010_2025-01-09_21-51-22')\n",
      "- train_tune_7c0ec_00004: FileNotFoundError('Could not fetch metrics for train_tune_7c0ec_00004: both result.json and progress.csv were not found at C:/Users/ilian/ray_results/train_tune_2025-01-09_21-51-22/train_tune_7c0ec_00004_4_dropout_prob=0.5000,lr=0.0010_2025-01-09_21-51-22')\n",
      "- train_tune_7c0ec_00005: FileNotFoundError('Could not fetch metrics for train_tune_7c0ec_00005: both result.json and progress.csv were not found at C:/Users/ilian/ray_results/train_tune_2025-01-09_21-51-22/train_tune_7c0ec_00005_5_dropout_prob=0.7000,lr=0.0010_2025-01-09_21-51-22')\n",
      "- train_tune_7c0ec_00006: FileNotFoundError('Could not fetch metrics for train_tune_7c0ec_00006: both result.json and progress.csv were not found at C:/Users/ilian/ray_results/train_tune_2025-01-09_21-51-22/train_tune_7c0ec_00006_6_dropout_prob=0.3000,lr=0.0100_2025-01-09_21-51-22')\n",
      "- train_tune_7c0ec_00007: FileNotFoundError('Could not fetch metrics for train_tune_7c0ec_00007: both result.json and progress.csv were not found at C:/Users/ilian/ray_results/train_tune_2025-01-09_21-51-22/train_tune_7c0ec_00007_7_dropout_prob=0.5000,lr=0.0100_2025-01-09_21-51-22')\n",
      "- train_tune_7c0ec_00008: FileNotFoundError('Could not fetch metrics for train_tune_7c0ec_00008: both result.json and progress.csv were not found at C:/Users/ilian/ray_results/train_tune_2025-01-09_21-51-22/train_tune_7c0ec_00008_8_dropout_prob=0.7000,lr=0.0100_2025-01-09_21-51-22')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import ray\n",
    "from ray import tune\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import models\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "\n",
    "\n",
    "torch.manual_seed(42)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "src_folder = Path.cwd()\n",
    "root_folder = src_folder.parent\n",
    "dataset_folder = os.path.join(root_folder, 'dataset')\n",
    "models_folder = os.path.join(root_folder, 'models')\n",
    "\n",
    "custom_folder = os.path.join(models_folder, 'custom')\n",
    "result_folder = os.path.join(custom_folder, 'results')\n",
    "\n",
    "PREPROCESSED_DIR = os.path.join(dataset_folder, 'preprocessed')\n",
    "CSV_PATH = os.path.join(dataset_folder, 'csv_mappings', 'train.csv')\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "NUM_CLASSES = 10\n",
    "EPOCHS = 20\n",
    "PATIENCE = 3\n",
    "\n",
    "class MushroomDataset(Dataset):\n",
    "    def __init__(self, preprocessed_dir, csv_path, transform=None):\n",
    "        self.preprocessed_dir = preprocessed_dir  \n",
    "        self.csv_path = csv_path  \n",
    "        self.transform = transform  \n",
    "        self.csv_data = pd.read_csv(csv_path)\n",
    "        \n",
    "        self.image_ids = self.csv_data['Image'].values  \n",
    "        self.labels = self.csv_data['Mushroom'].values \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_ids)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image_id = self.image_ids[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        image_id_str = str(image_id).zfill(5)  \n",
    "        \n",
    "        image_path = os.path.join(self.preprocessed_dir, f\"{image_id_str}.pt\")\n",
    "        image = torch.load(image_path)  \n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "dataset = MushroomDataset(PREPROCESSED_DIR, CSV_PATH)\n",
    "indices = list(range(len(dataset)))\n",
    "train_indices, temp_indices = train_test_split(indices, test_size=0.3, random_state=42)\n",
    "val_indices, test_indices = train_test_split(temp_indices, test_size=0.5, random_state=42)\n",
    "train_subset = torch.utils.data.Subset(dataset, train_indices)\n",
    "val_subset = torch.utils.data.Subset(dataset, val_indices)\n",
    "test_subset = torch.utils.data.Subset(dataset, test_indices)\n",
    "\n",
    "train_loader = DataLoader(train_subset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_subset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_subset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "def save_model(model, optimizer, epoch, loss, accuracy, file_path):\n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': loss,\n",
    "        'accuracy': accuracy,\n",
    "    }\n",
    "    torch.save(checkpoint, file_path)\n",
    "    print(f\"Model saved to {file_path}\")\n",
    "\n",
    "def train_on_epoch(model, train_loader, criterion, optimizer, device, epoch, writer, scheduler):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for batch_idx, data in enumerate(tqdm(train_loader, desc=\"[Train]\")):\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "        batch_accuracy = 100.0 * correct / total\n",
    "        writer.add_scalar('Train/Loss', loss.item(), epoch * len(train_loader) + batch_idx)\n",
    "        writer.add_scalar('Train/Accuracy', batch_accuracy, epoch * len(train_loader) + batch_idx)\n",
    "\n",
    "    train_accuracy = 100.0 * correct / total\n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "\n",
    "    for param_group in optimizer.param_groups:\n",
    "        writer.add_scalar('Train/Learning Rate', param_group['lr'], epoch)\n",
    "\n",
    "    if scheduler:\n",
    "        scheduler.step()\n",
    "\n",
    "    return avg_train_loss, train_accuracy\n",
    "\n",
    "def validate_on_epoch(model, val_loader, criterion, optimizer, device, epoch, writer, best_val_loss, patience, epochs_no_improve, save_path):\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, data in enumerate(tqdm(val_loader, desc=\"[Val]\")):\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "            batch_accuracy = 100.0 * correct / total\n",
    "            writer.add_scalar('Validation/Loss', loss.item(), epoch * len(val_loader) + batch_idx)\n",
    "            writer.add_scalar('Validation/Accuracy', batch_accuracy, epoch * len(val_loader) + batch_idx)\n",
    "\n",
    "    val_accuracy = 100.0 * correct / total\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        epochs_no_improve = 0\n",
    "        save_model(model, optimizer, epoch, avg_val_loss, val_accuracy, save_path)\n",
    "        print(f\"Model saved to {save_path}\")\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "\n",
    "    if epochs_no_improve >= patience:\n",
    "        print(f\"Early stopping triggered at epoch {epoch + 1}\")\n",
    "        return best_val_loss, epochs_no_improve, True, val_accuracy \n",
    "\n",
    "    return best_val_loss, epochs_no_improve, False, val_accuracy\n",
    "\n",
    "def train_and_validate(model, train_loader, val_loader, criterion, optimizer, epochs, device, writer, scheduler, patience, save_path):\n",
    "    best_val_loss = float('inf')\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"\\nEpoch {epoch + 1}/{epochs}\")\n",
    "\n",
    "        train_loss, train_accuracy = train_on_epoch(model, train_loader, criterion, optimizer, device, epoch, writer, scheduler)\n",
    "        print(f\"Train Loss = {train_loss:.4f}, Train Acc = {train_accuracy:.2f}%\")\n",
    "\n",
    "        best_val_loss, epochs_no_improve, early_stop, val_accuracy = validate_on_epoch(\n",
    "            model, val_loader, criterion, optimizer, device, epoch, writer, best_val_loss, patience, epochs_no_improve, save_path\n",
    "        )\n",
    "        print(f\"Val Loss = {best_val_loss:.4f}, Val Acc = {val_accuracy:.2f}%\")\n",
    "\n",
    "        if early_stop:\n",
    "            break  \n",
    "\n",
    "    return model\n",
    "\n",
    "def evaluate_model(model, test_loader, criterion, device):\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_labels = []\n",
    "    all_predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(test_loader, desc=\"[Test]\"):\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "    test_accuracy = 100.0 * correct / total\n",
    "    avg_test_loss = test_loss / len(test_loader)\n",
    "\n",
    "    print(f\"Test Loss = {avg_test_loss:.4f}\")\n",
    "    print(f\"Test Accuracy = {test_accuracy:.2f}%\")\n",
    "    \n",
    "    return avg_test_loss, test_accuracy, all_labels, all_predictions\n",
    "\n",
    "def plot_confusion_matrix(all_labels, all_predictions, num_classes, save_path=None):\n",
    "    conf_matrix = confusion_matrix(all_labels, all_predictions, labels=np.arange(num_classes))\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", \n",
    "                xticklabels=np.arange(num_classes), yticklabels=np.arange(num_classes))\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "\n",
    "    if save_path:\n",
    "        os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "        plt.savefig(save_path)\n",
    "        print(f\"Confusion matrix saved to {save_path}\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def per_class_accuracy(all_labels, all_predictions, num_classes):\n",
    "    class_accuracies = []\n",
    "    \n",
    "    for i in range(num_classes):\n",
    "        class_indices = [j for j, label in enumerate(all_labels) if label == i]\n",
    "        class_predictions = [all_predictions[j] for j in class_indices]\n",
    "        class_labels = [all_labels[j] for j in class_indices]\n",
    "        \n",
    "        class_accuracy = accuracy_score(class_labels, class_predictions)\n",
    "        class_accuracies.append(class_accuracy)\n",
    "        print(f\"Accuracy class {i}: {class_accuracy:.4f}\")\n",
    "    \n",
    "    return class_accuracies\n",
    "\n",
    "def display_classification_report_as_dataframe(all_labels, all_predictions):\n",
    "    report_dict = classification_report(all_labels, all_predictions, target_names=[str(i) for i in range(len(set(all_labels)))], output_dict=True)\n",
    "    report_df = pd.DataFrame(report_dict).transpose()\n",
    "    display(report_df)\n",
    "    return report_df\n",
    "\n",
    "class EnhancedResNet(nn.Module):\n",
    "    def __init__(self, num_classes=10, dropout_prob=0.5):\n",
    "        super(EnhancedResNet, self).__init__()\n",
    "\n",
    "        self.resnet = models.resnet50(pretrained=True)  \n",
    "        self.resnet.fc = nn.Identity()\n",
    "        self.dropout = nn.Dropout(p=dropout_prob)\n",
    "        \n",
    "        self.fc1 = nn.Linear(2048, 1024)  \n",
    "        self.fc2 = nn.Linear(1024, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.resnet(x)  \n",
    "        x = self.dropout(x) \n",
    "        x = torch.relu(self.fc1(x)) \n",
    "        x = self.fc2(x)  \n",
    "        return x\n",
    "\n",
    "def get_optimizer_and_scheduler(model, lr=0.001, weight_decay=1e-5, momentum=0.9):\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    \n",
    "    scheduler = OneCycleLR(\n",
    "        optimizer,\n",
    "        max_lr=lr,  \n",
    "        steps_per_epoch=len(train_loader),\n",
    "        epochs=EPOCHS,\n",
    "        pct_start=0.3,\n",
    "        anneal_strategy='cos',\n",
    "        div_factor=25.0,\n",
    "        final_div_factor=10000.0\n",
    "    )\n",
    "    \n",
    "    return optimizer, scheduler\n",
    "\n",
    "def set_model_for_training(model_type, dropout_prob=0.5):\n",
    "    base_log_path = os.path.join(custom_folder, model_type, 'log')\n",
    "    base_result_path = os.path.join(custom_folder, model_type, 'results')\n",
    "\n",
    "    if os.path.exists(base_log_path):\n",
    "        shutil.rmtree(base_log_path)\n",
    "    os.makedirs(base_log_path, exist_ok=True)\n",
    "    os.makedirs(base_result_path, exist_ok=True)\n",
    "\n",
    "    if model_type == 'custom':\n",
    "        model = EnhancedResNet(num_classes=NUM_CLASSES, dropout_prob=dropout_prob)\n",
    "        save_path = os.path.join(base_result_path, \"model_custom.pth\")\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported model type\")\n",
    "    \n",
    "    writer = SummaryWriter(log_dir=base_log_path)\n",
    "\n",
    "    return model, save_path, writer\n",
    "\n",
    "def train_tune(config):\n",
    "    model_type = 'custom'\n",
    "    model, save_path, writer = set_model_for_training(model_type, dropout_prob=config[\"dropout_prob\"])\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer, scheduler = get_optimizer_and_scheduler(model, lr=config[\"lr\"])\n",
    "    model = train_and_validate(model, \n",
    "                               train_loader, \n",
    "                               val_loader, \n",
    "                               criterion, \n",
    "                               optimizer, \n",
    "                               epochs=EPOCHS, \n",
    "                               device=device, \n",
    "                               writer=writer, \n",
    "                               scheduler=scheduler, \n",
    "                               patience=PATIENCE, \n",
    "                               save_path=save_path)\n",
    "    avg_test_loss, test_accuracy, all_labels, all_predictions = evaluate_model(model, test_loader, criterion, device)\n",
    "    return test_accuracy\n",
    "\n",
    "search_space = {\n",
    "    \"lr\": tune.grid_search([0.0001, 0.001, 0.01]),\n",
    "    \"dropout_prob\": tune.grid_search([0.3, 0.5, 0.7])\n",
    "}\n",
    "\n",
    "scheduler = ASHAScheduler(\n",
    "    metric=\"accuracy\",\n",
    "    mode=\"max\",\n",
    "    max_t=EPOCHS,\n",
    "    grace_period=1,\n",
    "    reduction_factor=2)\n",
    "\n",
    "analysis = tune.run(\n",
    "    train_tune,\n",
    "    config=search_space,\n",
    "    scheduler=scheduler,\n",
    "    num_samples=1,\n",
    "    resources_per_trial={\"cpu\": 1, \"gpu\": 1}\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
