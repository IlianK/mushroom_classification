{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC_DIR = Path.cwd()\n",
    "ROOT_DIR = SRC_DIR.parent\n",
    "\n",
    "DATA_DIR = os.path.join(ROOT_DIR, 'dataset')\n",
    "PREPROCESSED_DIR = os.path.join(DATA_DIR, 'preprocessed')\n",
    "CSV_PATH = os.path.join(DATA_DIR, 'csv_mappings', 'train.csv')\n",
    "\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, 'models')\n",
    "BASELINE_DIR = os.path.join(MODEL_DIR, 'baselines')\n",
    "BASELINE_FINETUNED_DIR = os.path.join(MODEL_DIR, 'baselines_finetuned')\n",
    "RESULT_DIR = os.path.join(BASELINE_DIR, 'results')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASS_NAMES = {\n",
    "    0: \"amanita\",\n",
    "    1: \"boletus\",\n",
    "    2: \"chantelle\",\n",
    "    3: \"deterrimus\",\n",
    "    4: \"rufus\",\n",
    "    5: \"torminosus\",\n",
    "    6: \"aurantiacum\",\n",
    "    7: \"procera\",\n",
    "    8: \"involutus\",\n",
    "    9: \"russula\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader, test_loader = training.get_data_loaders(PREPROCESSED_DIR, CSV_PATH, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "NUM_CLASSES = 10 \n",
    "EPOCHS = 20\n",
    "PATIENCE = 3\n",
    "LEARNING_RATE = 0.0001\n",
    "\n",
    "SCHEDULER = 'StepLR' # StepLR # OneCycleLR # None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Set model to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "SET_GET_MODEL = 'SET'\n",
    "WRITE = True\n",
    "FINETUNE = True    # True False\n",
    "model_type = 'custom_resnet'  \n",
    "# alexnet # resnet # vgg16 # densenet # efficientnet\n",
    "# custom_alexnet custom_resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SET_GET_MODEL == 'SET':\n",
    "    model, optimizer, criterion, scheduler, save_path, writer = training.set_model_for_training(\n",
    "    model_type, train_loader, EPOCHS, LEARNING_RATE, NUM_CLASSES, DEVICE, SCHEDULER, FINETUNE, WRITE)\n",
    "if SET_GET_MODEL == 'GET':\n",
    "    model = training.load_model_for_explaining(model_type, NUM_CLASSES, DEVICE, finetuned=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = training.train_and_validate(\n",
    "                            model, \n",
    "                            train_loader, \n",
    "                            val_loader, \n",
    "                            criterion, \n",
    "                            optimizer, \n",
    "                            epochs=EPOCHS, \n",
    "                            device=DEVICE, \n",
    "                            writer=writer, \n",
    "                            scheduler=scheduler, \n",
    "                            patience=PATIENCE, \n",
    "                            save_path=os.path.join(save_path, f'{model_type}.pth')\n",
    "                            )\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_test_loss, test_accuracy, all_labels, all_predictions, all_pred_probs = training.evaluate_model(\n",
    "    model, test_loader, criterion, DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Per class accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_class_acc = training.per_class_accuracy(all_labels, all_predictions, NUM_CLASSES, CLASS_NAMES, save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_df = training.display_classification_report(all_labels, all_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training.plot_confusion_matrix(all_labels, all_predictions, NUM_CLASSES, save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ROC Curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Precision Recall Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training.plot_roc_curve(all_labels, all_pred_probs, num_classes=10, save_path=save_path)\n",
    "training.plot_precision_recall_curve(all_labels, all_pred_probs, num_classes=10, save_path=save_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Save evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training.save_evaluation_results(\n",
    "    save_path=save_path,\n",
    "    avg_test_loss=avg_test_loss,\n",
    "    test_accuracy=test_accuracy,\n",
    "    all_labels=all_labels, \n",
    "    all_predictions=all_predictions,\n",
    "    per_class_acc=per_class_acc,\n",
    "    num_classes=NUM_CLASSES\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
