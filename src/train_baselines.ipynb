{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import models, transforms\n",
    "from torchvision.models import AlexNet_Weights\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, accuracy_score\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x186701620b0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_folder = Path.cwd()\n",
    "root_folder = src_folder.parent\n",
    "dataset_folder = os.path.join(root_folder, 'dataset')\n",
    "models_folder = os.path.join(root_folder, 'models')\n",
    "\n",
    "baseline_folder = os.path.join(models_folder, 'baselines')\n",
    "result_folder = os.path.join(baseline_folder, 'results')\n",
    "\n",
    "PREPROCESSED_DIR = os.path.join(dataset_folder, 'preprocessed')\n",
    "CSV_PATH = os.path.join(dataset_folder, 'csv_mappings', 'train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "NUM_CLASSES = 10 \n",
    "EPOCHS = 20\n",
    "PATIENCE = 3\n",
    "LEARNING_RATE = 0.0001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preperation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mushroom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MushroomDataset(Dataset):\n",
    "    def __init__(self, preprocessed_dir, csv_path, transform=None):\n",
    "        self.preprocessed_dir = preprocessed_dir  \n",
    "        self.csv_path = csv_path  \n",
    "        self.transform = transform  \n",
    "        self.csv_data = pd.read_csv(csv_path)\n",
    "        \n",
    "        # Images and Labels\n",
    "        self.image_ids = self.csv_data['Image'].values  \n",
    "        self.labels = self.csv_data['Mushroom'].values \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_ids)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image_id = self.image_ids[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        image_id_str = str(image_id).zfill(5)  # Pad for filename\n",
    "        \n",
    "        # Load .pt files\n",
    "        image_path = os.path.join(self.preprocessed_dir, f\"{image_id_str}.pt\")\n",
    "        image = torch.load(image_path)  \n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MushroomDataset(PREPROCESSED_DIR, CSV_PATH)\n",
    "indices = list(range(len(dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices, temp_indices = train_test_split(indices, test_size=0.3, random_state=42)\n",
    "val_indices, test_indices = train_test_split(temp_indices, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_subset = torch.utils.data.Subset(dataset, train_indices)\n",
    "val_subset = torch.utils.data.Subset(dataset, val_indices)\n",
    "test_subset = torch.utils.data.Subset(dataset, test_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_subset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_subset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_subset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train & Test functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, optimizer, epoch, loss, accuracy, file_path):\n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': loss,\n",
    "        'accuracy': accuracy,\n",
    "    }\n",
    "\n",
    "    torch.save(checkpoint, file_path)\n",
    "    print(f\"Model saved to {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_on_epoch(model, train_loader, criterion, optimizer, device, epoch, writer, scheduler):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    # Training loop\n",
    "    for batch_idx, data in enumerate(tqdm(train_loader, desc=\"[Train]\")):\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "        # Log loss and accuracy per batch to TensorBoard\n",
    "        batch_accuracy = 100.0 * correct / total\n",
    "        writer.add_scalar('Train/Loss', loss.item(), epoch * len(train_loader) + batch_idx)\n",
    "        writer.add_scalar('Train/Accuracy', batch_accuracy, epoch * len(train_loader) + batch_idx)\n",
    "\n",
    "    train_accuracy = 100.0 * correct / total\n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "\n",
    "    # Log the learning rate\n",
    "    for param_group in optimizer.param_groups:\n",
    "        writer.add_scalar('Train/Learning Rate', param_group['lr'], epoch)\n",
    "\n",
    "    # Step the scheduler\n",
    "    if scheduler:\n",
    "        scheduler.step()\n",
    "\n",
    "    return avg_train_loss, train_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_on_epoch(model, val_loader, criterion, optimizer, device, epoch, writer, best_val_loss, patience, epochs_no_improve, save_path):\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, data in enumerate(tqdm(val_loader, desc=\"[Val]\")):\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "            # Log loss and accuracy per batch to TensorBoard\n",
    "            batch_accuracy = 100.0 * correct / total\n",
    "            writer.add_scalar('Validation/Loss', loss.item(), epoch * len(val_loader) + batch_idx)\n",
    "            writer.add_scalar('Validation/Accuracy', batch_accuracy, epoch * len(val_loader) + batch_idx)\n",
    "\n",
    "    val_accuracy = 100.0 * correct / total\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "\n",
    "    # Early stopping \n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        epochs_no_improve = 0\n",
    "        save_model(model, optimizer, epoch, avg_val_loss, val_accuracy, save_path)\n",
    "        print(f\"Model saved to {save_path}\")\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "\n",
    "    if epochs_no_improve >= patience:\n",
    "        print(f\"Early stopping triggered at epoch {epoch + 1}\")\n",
    "        return best_val_loss, epochs_no_improve, True, val_accuracy \n",
    "\n",
    "    return best_val_loss, epochs_no_improve, False, val_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_validate(model, train_loader, val_loader, criterion, optimizer, epochs, device, writer, scheduler, patience, save_path):\n",
    "    best_val_loss = float('inf')\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"\\nEpoch {epoch + 1}/{epochs}\")\n",
    "\n",
    "        # Train\n",
    "        train_loss, train_accuracy = train_on_epoch(model, train_loader, criterion, optimizer, device, epoch, writer, scheduler)\n",
    "        print(f\"Train Loss = {train_loss:.4f}, Train Acc = {train_accuracy:.2f}%\")\n",
    "\n",
    "        # Validate\n",
    "        best_val_loss, epochs_no_improve, early_stop, val_accuracy = validate_on_epoch(\n",
    "            model, val_loader, criterion, optimizer, device, epoch, writer, best_val_loss, patience, epochs_no_improve, save_path\n",
    "        )\n",
    "        print(f\"Val Loss = {best_val_loss:.4f}, Val Acc = {val_accuracy:.2f}%\")\n",
    "\n",
    "        if early_stop:\n",
    "            break  \n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader, criterion, device):\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_labels = []\n",
    "    all_predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(test_loader, desc=\"[Test]\"):\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "            # Store preds and labels for plots\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "    test_accuracy = 100.0 * correct / total\n",
    "    avg_test_loss = test_loss / len(test_loader)\n",
    "\n",
    "    print(f\"Test Loss = {avg_test_loss:.4f}\")\n",
    "    print(f\"Test Accuracy = {test_accuracy:.2f}%\")\n",
    "    \n",
    "    return avg_test_loss, test_accuracy, all_labels, all_predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(all_labels, all_predictions, num_classes, save_path=None):\n",
    "    conf_matrix = confusion_matrix(all_labels, all_predictions, labels=np.arange(num_classes))\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", \n",
    "                xticklabels=np.arange(num_classes), yticklabels=np.arange(num_classes))\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "\n",
    "    if save_path:\n",
    "        os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "        plt.savefig(save_path)\n",
    "        print(f\"Confusion matrix saved to {save_path}\")\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def per_class_accuracy(all_labels, all_predictions, num_classes):\n",
    "    class_accuracies = []\n",
    "    \n",
    "    for i in range(num_classes):\n",
    "        class_indices = [j for j, label in enumerate(all_labels) if label == i]\n",
    "        class_predictions = [all_predictions[j] for j in class_indices]\n",
    "        class_labels = [all_labels[j] for j in class_indices]\n",
    "        \n",
    "        class_accuracy = accuracy_score(class_labels, class_predictions)\n",
    "        class_accuracies.append(class_accuracy)\n",
    "        print(f\"Accuracy class {i}: {class_accuracy:.4f}\")\n",
    "    \n",
    "    return class_accuracies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_classification_report_as_dataframe(all_labels, all_predictions):\n",
    "    report_dict = classification_report(all_labels, all_predictions, target_names=[str(i) for i in range(len(set(all_labels)))], output_dict=True)\n",
    "    report_df = pd.DataFrame(report_dict).transpose()\n",
    "    display(report_df)\n",
    "    return report_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretrained Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pretrained AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_alexnet = models.alexnet(weights=AlexNet_Weights.IMAGENET1K_V1)\n",
    "model_alexnet.classifier[6] = nn.Linear(model_alexnet.classifier[6].in_features, NUM_CLASSES)\n",
    "model_alexnet = model_alexnet.to(device)\n",
    "\n",
    "optimizer_alexnet = optim.AdamW(model_alexnet.parameters(), lr=LEARNING_RATE)\n",
    "save_path_alexnet = os.path.join(result_folder, \"model_alexnet.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pretrained ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_resnet = models.resnet50(weights='IMAGENET1K_V1') \n",
    "model_resnet.fc = nn.Linear(model_resnet.fc.in_features, NUM_CLASSES)  \n",
    "model_resnet = model_resnet.to(device)\n",
    "\n",
    "optimizer_resnet = optim.AdamW(model_resnet.parameters(), lr=LEARNING_RATE)\n",
    "save_path_resnet = os.path.join(result_folder, \"model_resnet.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pretrained VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vgg16 = models.vgg16(weights='IMAGENET1K_V1')\n",
    "model_vgg16.classifier[6] = nn.Linear(model_vgg16.classifier[6].in_features, NUM_CLASSES)\n",
    "model_vgg16 = model_vgg16.to(device)\n",
    "\n",
    "optimizer_vgg16 = optim.AdamW(model_vgg16.parameters(), lr=LEARNING_RATE)\n",
    "save_path_vgg16 = os.path.join(result_folder, \"model_vgg16.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pretrained DenseNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_densenet = models.densenet121(weights='IMAGENET1K_V1')\n",
    "model_densenet.classifier = nn.Linear(model_densenet.classifier.in_features, NUM_CLASSES)\n",
    "model_densenet = model_densenet.to(device)\n",
    "\n",
    "optimizer_densenet = optim.AdamW(model_densenet.parameters(), lr=LEARNING_RATE)\n",
    "save_path_densenet = os.path.join(result_folder, \"model_densenet.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pretrained EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_efficientnet = models.efficientnet_b0(weights='IMAGENET1K_V1')\n",
    "model_efficientnet.classifier[1] = nn.Linear(model_efficientnet.classifier[1].in_features, NUM_CLASSES)\n",
    "model_efficientnet = model_efficientnet.to(device)\n",
    "\n",
    "optimizer_efficientnet = optim.AdamW(model_efficientnet.parameters(), lr=LEARNING_RATE)\n",
    "save_path_efficientnet = os.path.join(result_folder, \"model_efficientnet.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setter for model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_model_for_training(model_type):\n",
    "    base_log_path = os.path.join(baseline_folder, model_type, 'log')\n",
    "    base_result_path = os.path.join(baseline_folder, model_type, 'results')\n",
    "\n",
    "    if os.path.exists(base_log_path):\n",
    "        shutil.rmtree(base_log_path)\n",
    "    os.makedirs(base_log_path, exist_ok=True)\n",
    "    os.makedirs(base_result_path, exist_ok=True)\n",
    "\n",
    "    if model_type == 'alexnet':\n",
    "        model = model_alexnet\n",
    "        optimizer = optimizer_alexnet\n",
    "        save_path = os.path.join(base_result_path, \"model_alexnet.pth\")\n",
    "\n",
    "    elif model_type == 'resnet':\n",
    "        model = model_resnet\n",
    "        optimizer = optimizer_resnet\n",
    "        save_path = os.path.join(base_result_path, \"model_resnet.pth\")\n",
    "\n",
    "    elif model_type == 'vgg16':\n",
    "        model = model_vgg16\n",
    "        optimizer = optimizer_vgg16\n",
    "        save_path = os.path.join(base_result_path, \"model_vgg16.pth\")\n",
    "\n",
    "    elif model_type == 'densenet':\n",
    "        model = model_densenet\n",
    "        optimizer = optimizer_densenet\n",
    "        save_path = os.path.join(base_result_path, \"model_densenet.pth\")\n",
    "\n",
    "    elif model_type == 'efficientnet':\n",
    "        model = model_efficientnet\n",
    "        optimizer = optimizer_efficientnet\n",
    "        save_path = os.path.join(base_result_path, \"model_efficientnet.pth\")\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported model type\")\n",
    "    \n",
    "    writer = SummaryWriter(log_dir=base_log_path)\n",
    "    print(model)\n",
    "    \n",
    "    return model, optimizer, save_path, writer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = 'efficientnet' # alexnet # resnet # vgg16 # densenet # efficientnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EfficientNet(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2dNormActivation(\n",
      "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): SiLU(inplace=True)\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (2): Conv2dNormActivation(\n",
      "            (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
      "            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(96, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(4, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): Conv2dNormActivation(\n",
      "            (0): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.0125, mode=row)\n",
      "      )\n",
      "      (1): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
      "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): Conv2dNormActivation(\n",
      "            (0): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.025, mode=row)\n",
      "      )\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(144, 144, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=144, bias=False)\n",
      "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): Conv2dNormActivation(\n",
      "            (0): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.037500000000000006, mode=row)\n",
      "      )\n",
      "      (1): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
      "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): Conv2dNormActivation(\n",
      "            (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.05, mode=row)\n",
      "      )\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
      "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): Conv2dNormActivation(\n",
      "            (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.0625, mode=row)\n",
      "      )\n",
      "      (1): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
      "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): Conv2dNormActivation(\n",
      "            (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.07500000000000001, mode=row)\n",
      "      )\n",
      "      (2): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
      "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): Conv2dNormActivation(\n",
      "            (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.08750000000000001, mode=row)\n",
      "      )\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
      "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): Conv2dNormActivation(\n",
      "            (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.1, mode=row)\n",
      "      )\n",
      "      (1): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
      "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): Conv2dNormActivation(\n",
      "            (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.1125, mode=row)\n",
      "      )\n",
      "      (2): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
      "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): Conv2dNormActivation(\n",
      "            (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.125, mode=row)\n",
      "      )\n",
      "    )\n",
      "    (6): Sequential(\n",
      "      (0): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
      "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): Conv2dNormActivation(\n",
      "            (0): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.1375, mode=row)\n",
      "      )\n",
      "      (1): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
      "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): Conv2dNormActivation(\n",
      "            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.15000000000000002, mode=row)\n",
      "      )\n",
      "      (2): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
      "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): Conv2dNormActivation(\n",
      "            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.1625, mode=row)\n",
      "      )\n",
      "      (3): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
      "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): Conv2dNormActivation(\n",
      "            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.17500000000000002, mode=row)\n",
      "      )\n",
      "    )\n",
      "    (7): Sequential(\n",
      "      (0): MBConv(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
      "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): SiLU(inplace=True)\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (3): Conv2dNormActivation(\n",
      "            (0): Conv2d(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.1875, mode=row)\n",
      "      )\n",
      "    )\n",
      "    (8): Conv2dNormActivation(\n",
      "      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): SiLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0.2, inplace=True)\n",
      "    (1): Linear(in_features=1280, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model, optimizer, save_path, writer = set_model_for_training(model_type)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = StepLR(optimizer, step_size=2, gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Train]:   0%|          | 0/52 [00:00<?, ?it/s]C:\\Users\\Micha\\AppData\\Local\\Temp\\ipykernel_46560\\2605163665.py:23: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  image = torch.load(image_path)\n",
      "[Train]: 100%|██████████| 52/52 [00:04<00:00, 12.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss = 2.0501, Train Acc = 36.01%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Val]: 100%|██████████| 12/12 [00:00<00:00, 29.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to g:\\Benutzer\\X_Ichigo_X\\Dokumente\\FH_Master\\Ki_labor\\Mushroom\\models\\baselines\\efficientnet\\results\\model_efficientnet.pth\n",
      "Model saved to g:\\Benutzer\\X_Ichigo_X\\Dokumente\\FH_Master\\Ki_labor\\Mushroom\\models\\baselines\\efficientnet\\results\\model_efficientnet.pth\n",
      "Val Loss = 1.6444, Val Acc = 61.97%\n",
      "\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Train]: 100%|██████████| 52/52 [00:03<00:00, 15.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss = 1.2615, Train Acc = 72.99%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Val]: 100%|██████████| 12/12 [00:00<00:00, 30.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to g:\\Benutzer\\X_Ichigo_X\\Dokumente\\FH_Master\\Ki_labor\\Mushroom\\models\\baselines\\efficientnet\\results\\model_efficientnet.pth\n",
      "Model saved to g:\\Benutzer\\X_Ichigo_X\\Dokumente\\FH_Master\\Ki_labor\\Mushroom\\models\\baselines\\efficientnet\\results\\model_efficientnet.pth\n",
      "Val Loss = 0.9116, Val Acc = 77.46%\n",
      "\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Train]: 100%|██████████| 52/52 [00:03<00:00, 14.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss = 0.7606, Train Acc = 83.63%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Val]: 100%|██████████| 12/12 [00:00<00:00, 32.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to g:\\Benutzer\\X_Ichigo_X\\Dokumente\\FH_Master\\Ki_labor\\Mushroom\\models\\baselines\\efficientnet\\results\\model_efficientnet.pth\n",
      "Model saved to g:\\Benutzer\\X_Ichigo_X\\Dokumente\\FH_Master\\Ki_labor\\Mushroom\\models\\baselines\\efficientnet\\results\\model_efficientnet.pth\n",
      "Val Loss = 0.7432, Val Acc = 81.13%\n",
      "\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Train]: 100%|██████████| 52/52 [00:03<00:00, 14.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss = 0.5674, Train Acc = 87.25%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Val]: 100%|██████████| 12/12 [00:00<00:00, 32.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to g:\\Benutzer\\X_Ichigo_X\\Dokumente\\FH_Master\\Ki_labor\\Mushroom\\models\\baselines\\efficientnet\\results\\model_efficientnet.pth\n",
      "Model saved to g:\\Benutzer\\X_Ichigo_X\\Dokumente\\FH_Master\\Ki_labor\\Mushroom\\models\\baselines\\efficientnet\\results\\model_efficientnet.pth\n",
      "Val Loss = 0.6130, Val Acc = 83.38%\n",
      "\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Train]: 100%|██████████| 52/52 [00:03<00:00, 14.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss = 0.4393, Train Acc = 90.82%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Val]: 100%|██████████| 12/12 [00:00<00:00, 32.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to g:\\Benutzer\\X_Ichigo_X\\Dokumente\\FH_Master\\Ki_labor\\Mushroom\\models\\baselines\\efficientnet\\results\\model_efficientnet.pth\n",
      "Model saved to g:\\Benutzer\\X_Ichigo_X\\Dokumente\\FH_Master\\Ki_labor\\Mushroom\\models\\baselines\\efficientnet\\results\\model_efficientnet.pth\n",
      "Val Loss = 0.5754, Val Acc = 83.94%\n",
      "\n",
      "Epoch 6/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Train]: 100%|██████████| 52/52 [00:03<00:00, 15.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss = 0.3876, Train Acc = 92.21%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Val]: 100%|██████████| 12/12 [00:00<00:00, 31.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to g:\\Benutzer\\X_Ichigo_X\\Dokumente\\FH_Master\\Ki_labor\\Mushroom\\models\\baselines\\efficientnet\\results\\model_efficientnet.pth\n",
      "Model saved to g:\\Benutzer\\X_Ichigo_X\\Dokumente\\FH_Master\\Ki_labor\\Mushroom\\models\\baselines\\efficientnet\\results\\model_efficientnet.pth\n",
      "Val Loss = 0.5428, Val Acc = 84.79%\n",
      "\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Train]: 100%|██████████| 52/52 [00:03<00:00, 15.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss = 0.3337, Train Acc = 93.84%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Val]: 100%|██████████| 12/12 [00:00<00:00, 34.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to g:\\Benutzer\\X_Ichigo_X\\Dokumente\\FH_Master\\Ki_labor\\Mushroom\\models\\baselines\\efficientnet\\results\\model_efficientnet.pth\n",
      "Model saved to g:\\Benutzer\\X_Ichigo_X\\Dokumente\\FH_Master\\Ki_labor\\Mushroom\\models\\baselines\\efficientnet\\results\\model_efficientnet.pth\n",
      "Val Loss = 0.5224, Val Acc = 84.79%\n",
      "\n",
      "Epoch 8/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Train]: 100%|██████████| 52/52 [00:03<00:00, 15.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss = 0.2990, Train Acc = 94.26%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Val]: 100%|██████████| 12/12 [00:00<00:00, 33.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to g:\\Benutzer\\X_Ichigo_X\\Dokumente\\FH_Master\\Ki_labor\\Mushroom\\models\\baselines\\efficientnet\\results\\model_efficientnet.pth\n",
      "Model saved to g:\\Benutzer\\X_Ichigo_X\\Dokumente\\FH_Master\\Ki_labor\\Mushroom\\models\\baselines\\efficientnet\\results\\model_efficientnet.pth\n",
      "Val Loss = 0.5047, Val Acc = 84.23%\n",
      "\n",
      "Epoch 9/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Train]: 100%|██████████| 52/52 [00:03<00:00, 15.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss = 0.2908, Train Acc = 95.23%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Val]: 100%|██████████| 12/12 [00:00<00:00, 32.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to g:\\Benutzer\\X_Ichigo_X\\Dokumente\\FH_Master\\Ki_labor\\Mushroom\\models\\baselines\\efficientnet\\results\\model_efficientnet.pth\n",
      "Model saved to g:\\Benutzer\\X_Ichigo_X\\Dokumente\\FH_Master\\Ki_labor\\Mushroom\\models\\baselines\\efficientnet\\results\\model_efficientnet.pth\n",
      "Val Loss = 0.4923, Val Acc = 85.35%\n",
      "\n",
      "Epoch 10/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Train]: 100%|██████████| 52/52 [00:03<00:00, 15.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss = 0.2777, Train Acc = 95.17%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Val]: 100%|██████████| 12/12 [00:00<00:00, 34.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to g:\\Benutzer\\X_Ichigo_X\\Dokumente\\FH_Master\\Ki_labor\\Mushroom\\models\\baselines\\efficientnet\\results\\model_efficientnet.pth\n",
      "Model saved to g:\\Benutzer\\X_Ichigo_X\\Dokumente\\FH_Master\\Ki_labor\\Mushroom\\models\\baselines\\efficientnet\\results\\model_efficientnet.pth\n",
      "Val Loss = 0.4913, Val Acc = 86.20%\n",
      "\n",
      "Epoch 11/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Train]: 100%|██████████| 52/52 [00:03<00:00, 15.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss = 0.2664, Train Acc = 95.53%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Val]: 100%|██████████| 12/12 [00:00<00:00, 33.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss = 0.4913, Val Acc = 85.92%\n",
      "\n",
      "Epoch 12/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Train]: 100%|██████████| 52/52 [00:03<00:00, 15.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss = 0.2717, Train Acc = 94.92%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Val]: 100%|██████████| 12/12 [00:00<00:00, 33.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to g:\\Benutzer\\X_Ichigo_X\\Dokumente\\FH_Master\\Ki_labor\\Mushroom\\models\\baselines\\efficientnet\\results\\model_efficientnet.pth\n",
      "Model saved to g:\\Benutzer\\X_Ichigo_X\\Dokumente\\FH_Master\\Ki_labor\\Mushroom\\models\\baselines\\efficientnet\\results\\model_efficientnet.pth\n",
      "Val Loss = 0.4835, Val Acc = 85.63%\n",
      "\n",
      "Epoch 13/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Train]: 100%|██████████| 52/52 [00:03<00:00, 15.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss = 0.2666, Train Acc = 95.59%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Val]: 100%|██████████| 12/12 [00:00<00:00, 34.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss = 0.4835, Val Acc = 85.07%\n",
      "\n",
      "Epoch 14/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Train]: 100%|██████████| 52/52 [00:03<00:00, 15.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss = 0.2560, Train Acc = 95.59%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Val]: 100%|██████████| 12/12 [00:00<00:00, 32.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to g:\\Benutzer\\X_Ichigo_X\\Dokumente\\FH_Master\\Ki_labor\\Mushroom\\models\\baselines\\efficientnet\\results\\model_efficientnet.pth\n",
      "Model saved to g:\\Benutzer\\X_Ichigo_X\\Dokumente\\FH_Master\\Ki_labor\\Mushroom\\models\\baselines\\efficientnet\\results\\model_efficientnet.pth\n",
      "Val Loss = 0.4787, Val Acc = 85.92%\n",
      "\n",
      "Epoch 15/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Train]: 100%|██████████| 52/52 [00:03<00:00, 15.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss = 0.2653, Train Acc = 95.29%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Val]: 100%|██████████| 12/12 [00:00<00:00, 34.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss = 0.4787, Val Acc = 86.20%\n",
      "\n",
      "Epoch 16/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Train]: 100%|██████████| 52/52 [00:03<00:00, 15.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss = 0.2732, Train Acc = 94.38%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Val]: 100%|██████████| 12/12 [00:00<00:00, 35.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss = 0.4787, Val Acc = 85.63%\n",
      "\n",
      "Epoch 17/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Train]: 100%|██████████| 52/52 [00:03<00:00, 15.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss = 0.2560, Train Acc = 94.86%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Val]: 100%|██████████| 12/12 [00:00<00:00, 33.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered at epoch 17\n",
      "Val Loss = 0.4787, Val Acc = 85.35%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = train_and_validate(model, \n",
    "                           train_loader, \n",
    "                           val_loader, \n",
    "                           criterion, \n",
    "                           optimizer, \n",
    "                           epochs=EPOCHS, \n",
    "                           device=device, \n",
    "                           writer=writer, \n",
    "                           scheduler=scheduler, \n",
    "                           patience=PATIENCE, \n",
    "                           save_path=save_path)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_results_path = os.path.join(os.path.dirname(save_path), \"evaluation_results.txt\")\n",
    "confusion_matrix_path = os.path.join(os.path.dirname(save_path), \"plot_confusion_matrix.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Test]:   0%|          | 0/12 [00:00<?, ?it/s]C:\\Users\\ilian\\AppData\\Local\\Temp\\ipykernel_20768\\2605163665.py:23: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  image = torch.load(image_path)\n",
      "[Test]: 100%|██████████| 12/12 [00:11<00:00,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss = 2.4103\n",
      "Test Accuracy = 11.83%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "avg_test_loss, test_accuracy, all_labels, all_predictions = evaluate_model(model, test_loader, criterion, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy class 0: 0.0000\n",
      "Accuracy class 1: 0.0213\n",
      "Accuracy class 2: 0.0000\n",
      "Accuracy class 3: 0.6471\n",
      "Accuracy class 4: 0.0286\n",
      "Accuracy class 5: 0.1500\n",
      "Accuracy class 6: 0.0000\n",
      "Accuracy class 7: 0.2857\n",
      "Accuracy class 8: 0.0741\n",
      "Accuracy class 9: 0.0000\n"
     ]
    }
   ],
   "source": [
    "per_class_acc = per_class_accuracy(all_labels, all_predictions, NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ilian\\Documents\\Projects\\git_projects\\university\\mushroom_classification\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\ilian\\Documents\\Projects\\git_projects\\university\\mushroom_classification\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\ilian\\Documents\\Projects\\git_projects\\university\\mushroom_classification\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>37.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.021277</td>\n",
       "      <td>0.033898</td>\n",
       "      <td>47.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>43.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.156028</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.251429</td>\n",
       "      <td>34.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>35.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>40.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>35.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.081633</td>\n",
       "      <td>27.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.118310</td>\n",
       "      <td>0.118310</td>\n",
       "      <td>0.118310</td>\n",
       "      <td>0.11831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.067547</td>\n",
       "      <td>0.120670</td>\n",
       "      <td>0.071469</td>\n",
       "      <td>355.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.069942</td>\n",
       "      <td>0.118310</td>\n",
       "      <td>0.071546</td>\n",
       "      <td>355.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score    support\n",
       "0              0.000000  0.000000  0.000000   37.00000\n",
       "1              0.083333  0.021277  0.033898   47.00000\n",
       "2              0.000000  0.000000  0.000000   43.00000\n",
       "3              0.156028  0.647059  0.251429   34.00000\n",
       "4              0.040000  0.028571  0.033333   35.00000\n",
       "5              0.214286  0.150000  0.176471   40.00000\n",
       "6              0.000000  0.000000  0.000000   30.00000\n",
       "7              0.090909  0.285714  0.137931   35.00000\n",
       "8              0.090909  0.074074  0.081633   27.00000\n",
       "9              0.000000  0.000000  0.000000   27.00000\n",
       "accuracy       0.118310  0.118310  0.118310    0.11831\n",
       "macro avg      0.067547  0.120670  0.071469  355.00000\n",
       "weighted avg   0.069942  0.118310  0.071546  355.00000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "report_df = display_classification_report_as_dataframe(all_labels, all_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix saved to c:\\Users\\ilian\\Documents\\Projects\\git_projects\\university\\mushroom_classification\\models\\baselines\\densenet\\results\\plot_confusion_matrix.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(all_labels, all_predictions, NUM_CLASSES, save_path=confusion_matrix_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ilian\\Documents\\Projects\\git_projects\\university\\mushroom_classification\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\ilian\\Documents\\Projects\\git_projects\\university\\mushroom_classification\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\ilian\\Documents\\Projects\\git_projects\\university\\mushroom_classification\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "with open(evaluation_results_path, 'w') as f:\n",
    "    f.write(f\"Test Loss = {avg_test_loss:.4f}\\n\")\n",
    "    f.write(f\"Test Accuracy = {test_accuracy:.2f}%\\n\")\n",
    "    f.write(\"\\nClassification Report:\\n\")\n",
    "    f.write(classification_report(all_labels, all_predictions, target_names=[str(i) for i in range(NUM_CLASSES)]))\n",
    "    f.write(\"\\nPer-Class Accuracy:\\n\")\n",
    "    for i, acc in enumerate(per_class_acc):\n",
    "        f.write(f\"Class {i}: {acc:.2f}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
