{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.transforms import functional as F\n",
    "from torch.utils.data import random_split\n",
    "import random\n",
    "from torchvision.transforms import ToPILImage\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create data with concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concepts = {\n",
    "    'cap_shape': ['convex', 'flat', 'bell-shaped', 'other'],\n",
    "    'cap_color': ['white', 'brown', 'yellow', 'red', 'other'],\n",
    "    'cap_texture': ['smooth', 'scaly', 'warty', 'other'],\n",
    "    'gill_attachment': ['free', 'attached', 'decurrent'],\n",
    "    'gill_color': ['white', 'brown', 'yellow', 'other'],\n",
    "    'stem_shape': ['cylindrical', 'club-shaped', 'bulbous'],\n",
    "    'stem_color': ['white', 'brown', 'yellow', 'other'],\n",
    "    'stem_texture': ['smooth', 'fibrous', 'scaly', 'other'],\n",
    "    'spore_print_color': ['white', 'brown', 'yellow', 'other']\n",
    "}\n",
    "\n",
    "class_concepts = {\n",
    "    0: {'cap_color': 'white'},\n",
    "    1: {'cap_shape': 'convex', 'cap_color': 'brown', 'spore_print_color': 'brown'},\n",
    "    2: {'cap_shape': 'convex', 'cap_color': 'yellow', 'gill_attachment': 'attached'},\n",
    "    3: {'cap_color': 'brown', 'gill_color': 'brown', 'stem_shape': 'cylindrical'},\n",
    "    4: {'cap_texture': 'smooth', 'gill_attachment': 'free', 'spore_print_color': 'white'},\n",
    "    5: {'cap_shape': 'convex', 'stem_color': 'brown', 'stem_texture': 'fibrous'},\n",
    "    6: {'cap_color': 'orange', 'cap_texture': 'smooth'},\n",
    "    7: {'cap_shape': 'flat', 'cap_texture': 'scaly', 'stem_shape': 'cylindrical'},\n",
    "    8: {'gill_attachment': 'decurrent', 'stem_color': 'white'},\n",
    "    9: {'cap_color': 'red', 'gill_color': 'white', 'spore_print_color': 'white'}\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = os.path.join(os.path.dirname(os.getcwd())) \n",
    "csv_path = os.path.join(root_path, \"dataset\", \"csv_mappings\")\n",
    "\n",
    "original_train_csv_path = os.path.join(csv_path, \"train.csv\")\n",
    "#original_test_csv_path = os.path.join(csv_path, \"test.csv\")\n",
    "\n",
    "train_with_concepts = os.path.join(csv_path, \"train_with_concepts.csv\")\n",
    "#test_with_concepts = os.path.join(csv_path, \"test_with_concepts.csv\")\n",
    "\n",
    "original_df = pd.read_csv(original_train_csv_path)\n",
    "#original_df = pd.read_csv(original_test_csv_path)\n",
    "\n",
    "def map_class_to_concepts(label):\n",
    "    return class_concepts[label]\n",
    "\n",
    "concept_encoders = {concept: LabelEncoder() for concept in concepts.keys()}\n",
    "\n",
    "for label, concept_values in class_concepts.items():\n",
    "    for concept, value in concept_values.items():\n",
    "        original_df.loc[original_df['Mushroom'] == label, concept] = value\n",
    "for concept, encoder in concept_encoders.items():\n",
    "    if concept in original_df.columns:\n",
    "        original_df[concept] = encoder.fit_transform(original_df[concept].fillna('other'))\n",
    "\n",
    "original_df.to_csv(train_with_concepts, index=False)\n",
    "print(f\"CSV with encoded concepts created at: {train_with_concepts}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create CBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreprocessedMushroomDataset(Dataset):\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        self.annotations = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.root_dir, f'{int(self.annotations.iloc[idx, 0]):05d}.pt')  # Ensure 5 digits\n",
    "        image = torch.load(img_name).float()\n",
    "        class_label = self.annotations.iloc[idx, 1].astype('float')\n",
    "        concept_labels = self.annotations.iloc[idx, 2:].values.astype('float')\n",
    "        labels = torch.tensor([class_label] + concept_labels.tolist())\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = os.path.join(os.path.dirname(os.getcwd()))\n",
    "preprocessed_train_path = os.path.join(root_path, 'dataset', 'preprocessed', 'train')\n",
    "preprocessed_test_path = os.path.join(root_path, 'dataset', 'preprocessed', 'test')\n",
    "train_csv_path = os.path.join(root_path, 'dataset', 'csv_mappings', 'train_with_concepts.csv')\n",
    "test_csv_path = os.path.join(root_path, 'dataset', 'csv_mappings', 'test_with_concepts.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dataset and Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = PreprocessedMushroomDataset(csv_file=train_csv_path, root_dir=preprocessed_train_path)\n",
    "#test_dataset = PreprocessedMushroomDataset(csv_file=test_csv_path, root_dir=preprocessed_test_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.8 * len(train_dataset))  # 80% for training\n",
    "val_size = len(train_dataset) - train_size  # 20% for validation\n",
    "\n",
    "train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "#test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Concept Bottleneck Model (CBM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConceptBottleneckModel(nn.Module):\n",
    "    def __init__(self, num_concepts, num_classes):\n",
    "        super(ConceptBottleneckModel, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.fc_concepts = nn.Sequential(\n",
    "            nn.Linear(128 * 56 * 56, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, num_concepts)\n",
    "        )\n",
    "        self.fc_task = nn.Sequential(\n",
    "            nn.Linear(num_concepts, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        concepts = self.fc_concepts(x)\n",
    "        output = self.fc_task(concepts)\n",
    "        return output, concepts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "num_concepts = 9\n",
    "num_classes = 10  \n",
    "\n",
    "model = ConceptBottleneckModel(num_concepts=num_concepts, num_classes=num_classes).to(device)\n",
    "criterion_task = nn.CrossEntropyLoss()\n",
    "criterion_concept = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 20\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Training \n",
    "    model.train() \n",
    "    running_loss = 0.0\n",
    "    running_task_loss = 0.0\n",
    "    running_concept_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "\n",
    "    for images, labels in train_dataloader:\n",
    "        images = images.to(device)\n",
    "        class_labels = labels[:, 0].to(device).long()  \n",
    "        concept_labels = labels[:, 1:].to(device).float()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs, predicted_concepts = model(images)\n",
    "\n",
    "        # Task concept losses\n",
    "        loss_task = criterion_task(outputs, class_labels)\n",
    "        loss_concepts = criterion_concept(predicted_concepts, concept_labels)\n",
    "\n",
    "        # Combined loss\n",
    "        alpha = 0.5 \n",
    "        loss = alpha * loss_task + (1 - alpha) * loss_concepts\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update losses\n",
    "        running_loss += loss.item()\n",
    "        running_task_loss += loss_task.item()\n",
    "        running_concept_loss += loss_concepts.item()\n",
    "\n",
    "        # Accuracy\n",
    "        _, predicted_classes = torch.max(outputs, 1)\n",
    "        correct_predictions += (predicted_classes == class_labels).sum().item()\n",
    "        total_predictions += class_labels.size(0)\n",
    "\n",
    "    # Average losses and accuracy for training\n",
    "    epoch_loss = running_loss / len(train_dataloader)\n",
    "    epoch_task_loss = running_task_loss / len(train_dataloader)\n",
    "    epoch_concept_loss = running_concept_loss / len(train_dataloader)\n",
    "    accuracy = correct_predictions / total_predictions * 100\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {epoch_loss:.4f}, \"\n",
    "          f\"Task Loss: {epoch_task_loss:.4f}, Concept Loss: {epoch_concept_loss:.4f}, \"\n",
    "          f\"Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "\n",
    "    # Validation \n",
    "    model.eval()  \n",
    "    val_running_loss = 0.0\n",
    "    val_running_task_loss = 0.0\n",
    "    val_running_concept_loss = 0.0\n",
    "    val_correct_predictions = 0\n",
    "    val_total_predictions = 0\n",
    "\n",
    "    with torch.no_grad(): \n",
    "        for images, labels in val_dataloader:\n",
    "            images = images.to(device)\n",
    "            class_labels = labels[:, 0].to(device).long()  \n",
    "            concept_labels = labels[:, 1:].to(device).float()\n",
    "\n",
    "            outputs, predicted_concepts = model(images)\n",
    "\n",
    "            # Task concept losses\n",
    "            loss_task = criterion_task(outputs, class_labels)\n",
    "            loss_concepts = criterion_concept(predicted_concepts, concept_labels)\n",
    "\n",
    "            # Combined loss\n",
    "            alpha = 0.5\n",
    "            loss = alpha * loss_task + (1 - alpha) * loss_concepts\n",
    "\n",
    "            # Update losses\n",
    "            val_running_loss += loss.item()\n",
    "            val_running_task_loss += loss_task.item()\n",
    "            val_running_concept_loss += loss_concepts.item()\n",
    "\n",
    "            # Accuracy\n",
    "            _, predicted_classes = torch.max(outputs, 1)\n",
    "            val_correct_predictions += (predicted_classes == class_labels).sum().item()\n",
    "            val_total_predictions += class_labels.size(0)\n",
    "\n",
    "    # Average validation losses and accuracy\n",
    "    val_epoch_loss = val_running_loss / len(val_dataloader)\n",
    "    val_epoch_task_loss = val_running_task_loss / len(val_dataloader)\n",
    "    val_epoch_concept_loss = val_running_concept_loss / len(val_dataloader)\n",
    "    val_accuracy = val_correct_predictions / val_total_predictions * 100\n",
    "\n",
    "    print(f\"Validation Loss: {val_epoch_loss:.4f}, \"\n",
    "          f\"Validation Task Loss: {val_epoch_task_loss:.4f}, \"\n",
    "          f\"Validation Concept Loss: {val_epoch_concept_loss:.4f}, \"\n",
    "          f\"Validation Accuracy: {val_accuracy:.2f}%\")\n",
    "\n",
    "print('Training and validation completed')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
