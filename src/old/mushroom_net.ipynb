{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from torchmetrics import Accuracy, Precision, Recall, F1Score, ConfusionMatrix\n",
    "from torchvision import models, transforms\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Class\n",
    "class PreprocessedMushroomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, csv_file, root_dir, has_labels=True):\n",
    "        self.annotations = pd.read_csv(csv_file, dtype={0: str})\n",
    "        self.root_dir = root_dir\n",
    "        self.has_labels = has_labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.root_dir, self.annotations.iloc[idx, 0] + '.pt')\n",
    "        image = torch.load(img_name) \n",
    "        label = int(self.annotations.iloc[idx, 1]) if self.has_labels else -1\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MushroomClassifier(pl.LightningModule):\n",
    "    def __init__(self, num_classes, lr=1e-3, weight_decay=0.01):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        \n",
    "        # Define model\n",
    "        self.model = models.alexnet(pretrained=False)\n",
    "        num_ftrs = self.model.classifier[6].in_features\n",
    "        self.model.classifier[6] = nn.Linear(num_ftrs, num_classes)\n",
    "\n",
    "        # Define loss and metrics\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.lr = lr\n",
    "        self.weight_decay = weight_decay\n",
    "        self.validation_outputs = []\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        images, labels = batch\n",
    "        outputs = self(images)\n",
    "        loss = self.criterion(outputs, labels)\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        images, labels = batch\n",
    "        outputs = self(images)\n",
    "        loss = self.criterion(outputs, labels)\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "\n",
    "        # Log validation loss\n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\n",
    "        self.validation_outputs.append((preds, labels))  \n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        preds, labels = zip(*self.validation_outputs)\n",
    "        preds = torch.cat(preds)\n",
    "        labels = torch.cat(labels)\n",
    "\n",
    "        # Compute accuracy manually\n",
    "        accuracy = (preds == labels).float().mean()\n",
    "\n",
    "        # Get the actual unique classes from the labels\n",
    "        unique_classes = torch.unique(labels)\n",
    "        class_names = [f\"Class {i}\" for i in unique_classes.tolist()] \n",
    "\n",
    "        # Compute metrics\n",
    "        metrics = classification_report(\n",
    "            labels.cpu(), preds.cpu(), target_names=class_names, output_dict=True\n",
    "        )\n",
    "        cm = confusion_matrix(labels.cpu(), preds.cpu())\n",
    "\n",
    "        # Log other metrics\n",
    "        self.log_dict({\n",
    "            \"val_accuracy\": accuracy,  # Log the computed accuracy\n",
    "            \"val_macro_precision\": metrics[\"macro avg\"][\"precision\"],\n",
    "            \"val_macro_recall\": metrics[\"macro avg\"][\"recall\"],\n",
    "            \"val_macro_f1\": metrics[\"macro avg\"][\"f1-score\"],\n",
    "        })\n",
    "\n",
    "        # Print confusion matrix and metrics\n",
    "        print(\"Confusion Matrix:\")\n",
    "        print(cm)\n",
    "        print(\"Classification Report:\")\n",
    "        print(classification_report(labels.cpu(), preds.cpu(), target_names=class_names))\n",
    "\n",
    "        # Clear validation outputs\n",
    "        self.validation_outputs.clear()\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = AdamW(\n",
    "            self.parameters(), \n",
    "            lr=self.lr,  # Learning rate\n",
    "            weight_decay=0.01  # Weight decay\n",
    "        )\n",
    "        \n",
    "        # Warm-up and scheduling with OneCycleLR\n",
    "        scheduler = {\n",
    "            'scheduler': OneCycleLR(\n",
    "                optimizer, \n",
    "                max_lr=self.lr,  # Peak learning rate\n",
    "                total_steps=self.trainer.estimated_stepping_batches,\n",
    "                pct_start=0.1,  # Warm-up phase percentage\n",
    "                anneal_strategy='cos',  # Cosine annealing after warm-up\n",
    "                div_factor=25.0  # Initial LR = max_lr/div_factor\n",
    "            ),\n",
    "            'interval': 'step',  # Apply the scheduler at every step\n",
    "            'frequency': 1  # Scheduler is updated every step\n",
    "        }\n",
    "        \n",
    "        return [optimizer], [scheduler]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "root_path = os.path.dirname(os.getcwd())\n",
    "models_path = os.path.join(root_path, 'models')\n",
    "dataset_path = os.path.join(root_path, 'dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "train_csv_path = os.path.join(dataset_path, 'csv_mappings/train.csv')\n",
    "test_csv_path = os.path.join(dataset_path, 'csv_mappings/test.csv')\n",
    "preprocessed_train_path = os.path.join(dataset_path, 'preprocessed/train')\n",
    "preprocessed_test_path = os.path.join(dataset_path, 'preprocessed/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = PreprocessedMushroomDataset(csv_file=train_csv_path, root_dir=preprocessed_train_path, has_labels=True)\n",
    "test_dataset = PreprocessedMushroomDataset(csv_file=test_csv_path, root_dir=preprocessed_test_path, has_labels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Dataset\n",
    "train_size = int(0.8 * len(train_dataset))\n",
    "val_size = len(train_dataset) - train_size\n",
    "train_subset, val_subset = random_split(train_dataset, [train_size, val_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloaders\n",
    "train_dataloader = DataLoader(train_subset, batch_size=8, shuffle=True)\n",
    "val_dataloader = DataLoader(val_subset, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ilian\\Documents\\Projects\\git_projects\\university\\mushroom_classification\\.venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ilian\\Documents\\Projects\\git_projects\\university\\mushroom_classification\\.venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Training parameters\n",
    "num_classes = len(train_dataset.annotations.iloc[:, 1].unique())\n",
    "learning_rate = 0.001\n",
    "weight_decay = 0.01\n",
    "\n",
    "# Model\n",
    "model = MushroomClassifier(num_classes=num_classes, lr=learning_rate, weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=models_path, \n",
    "    filename='mushroom_model_{epoch:02d}', \n",
    "    save_top_k=1, \n",
    "    monitor='val_accuracy',  # Monitor val_accuracy instead of val_acc\n",
    "    mode='max'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_callback = EarlyStopping(\n",
    "    monitor='val_accuracy',  # Monitor val_accuracy instead of val_acc\n",
    "    patience=5, \n",
    "    mode='max'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    max_epochs=1, \n",
    "    accelerator='gpu' if torch.cuda.is_available() else 'cpu',\n",
    "    callbacks=[checkpoint_callback, early_stopping_callback],\n",
    "    deterministic=True  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ilian\\Documents\\Projects\\git_projects\\university\\mushroom_classification\\.venv\\Lib\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:654: Checkpoint directory C:\\Users\\ilian\\Documents\\Projects\\git_projects\\university\\mushroom_classification\\models exists and is not empty.\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "c:\\Users\\ilian\\Documents\\Projects\\git_projects\\university\\mushroom_classification\\.venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=21` in the `DataLoader` to improve performance.\n",
      "\n",
      "  | Name      | Type             | Params | Mode \n",
      "-------------------------------------------------------\n",
      "0 | model     | AlexNet          | 57.0 M | train\n",
      "1 | criterion | CrossEntropyLoss | 0      | train\n",
      "-------------------------------------------------------\n",
      "57.0 M    Trainable params\n",
      "0         Non-trainable params\n",
      "57.0 M    Total params\n",
      "228.179   Total estimated model params size (MB)\n",
      "25        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ilian\\Documents\\Projects\\git_projects\\university\\mushroom_classification\\.venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=21` in the `DataLoader` to improve performance.\n",
      "C:\\Users\\ilian\\AppData\\Local\\Temp\\ipykernel_25948\\302768154.py:13: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  image = torch.load(img_name)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0: 100%|██████████| 2/2 [00:00<00:00,  4.40it/s]Confusion Matrix:\n",
      "[[0 0 0 0 0 0 0 1]\n",
      " [0 0 0 0 0 0 0 2]\n",
      " [0 0 0 0 0 0 0 2]\n",
      " [0 0 0 0 0 0 0 3]\n",
      " [0 0 0 0 0 0 0 1]\n",
      " [0 0 0 0 0 0 0 3]\n",
      " [0 0 0 0 0 0 0 2]\n",
      " [0 0 0 0 0 0 0 2]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.00      0.00      0.00         1\n",
      "     Class 1       0.00      0.00      0.00         2\n",
      "     Class 2       0.00      0.00      0.00         2\n",
      "     Class 4       0.00      0.00      0.00         3\n",
      "     Class 6       0.00      0.00      0.00         1\n",
      "     Class 7       0.00      0.00      0.00         3\n",
      "     Class 8       0.00      0.00      0.00         2\n",
      "     Class 9       0.12      1.00      0.22         2\n",
      "\n",
      "    accuracy                           0.12        16\n",
      "   macro avg       0.02      0.12      0.03        16\n",
      "weighted avg       0.02      0.12      0.03        16\n",
      "\n",
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ilian\\Documents\\Projects\\git_projects\\university\\mushroom_classification\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\ilian\\Documents\\Projects\\git_projects\\university\\mushroom_classification\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\ilian\\Documents\\Projects\\git_projects\\university\\mushroom_classification\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\ilian\\Documents\\Projects\\git_projects\\university\\mushroom_classification\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\ilian\\Documents\\Projects\\git_projects\\university\\mushroom_classification\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\ilian\\Documents\\Projects\\git_projects\\university\\mushroom_classification\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/237 [00:00<?, ?it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilian\\AppData\\Local\\Temp\\ipykernel_25948\\302768154.py:13: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  image = torch.load(img_name)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 237/237 [01:17<00:00,  3.05it/s, v_num=9]Confusion Matrix:\n",
      "[[ 0  0 30  0  0 14  0  0  0  1]\n",
      " [ 0  0 28  0  0 13  0  0  0  0]\n",
      " [ 0  0 33  0  0  9  0  0  0  1]\n",
      " [ 0  0 30  0  0 15  0  0  0  0]\n",
      " [ 0  0 38  0  0 18  0  0  0  1]\n",
      " [ 0  0 34  0  0 14  0  0  0  1]\n",
      " [ 0  0 33  0  0 15  0  0  0  1]\n",
      " [ 0  0 32  0  0 12  0  0  0  1]\n",
      " [ 0  0 31  0  0 22  0  0  0  0]\n",
      " [ 0  0 33  0  0 13  0  0  0  0]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.00      0.00      0.00        45\n",
      "     Class 1       0.00      0.00      0.00        41\n",
      "     Class 2       0.10      0.77      0.18        43\n",
      "     Class 3       0.00      0.00      0.00        45\n",
      "     Class 4       0.00      0.00      0.00        57\n",
      "     Class 5       0.10      0.29      0.14        49\n",
      "     Class 6       0.00      0.00      0.00        49\n",
      "     Class 7       0.00      0.00      0.00        45\n",
      "     Class 8       0.00      0.00      0.00        53\n",
      "     Class 9       0.00      0.00      0.00        46\n",
      "\n",
      "    accuracy                           0.10       473\n",
      "   macro avg       0.02      0.11      0.03       473\n",
      "weighted avg       0.02      0.10      0.03       473\n",
      "\n",
      "Epoch 0: 100%|██████████| 237/237 [01:24<00:00,  2.79it/s, v_num=9, val_loss=2.300]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ilian\\Documents\\Projects\\git_projects\\university\\mushroom_classification\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\ilian\\Documents\\Projects\\git_projects\\university\\mushroom_classification\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\ilian\\Documents\\Projects\\git_projects\\university\\mushroom_classification\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\ilian\\Documents\\Projects\\git_projects\\university\\mushroom_classification\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\ilian\\Documents\\Projects\\git_projects\\university\\mushroom_classification\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\ilian\\Documents\\Projects\\git_projects\\university\\mushroom_classification\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 237/237 [01:27<00:00,  2.71it/s, v_num=9, val_loss=2.300]\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "trainer.fit(model, train_dataloader, val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilian\\AppData\\Local\\Temp\\ipykernel_25948\\302768154.py:13: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  image = torch.load(img_name)\n",
      "c:\\Users\\ilian\\Documents\\Projects\\git_projects\\university\\mushroom_classification\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\ilian\\Documents\\Projects\\git_projects\\university\\mushroom_classification\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\ilian\\Documents\\Projects\\git_projects\\university\\mushroom_classification\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\ilian\\Documents\\Projects\\git_projects\\university\\mushroom_classification\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'int' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m class_names \u001b[38;5;241m=\u001b[39m train_dataset\u001b[38;5;241m.\u001b[39mannotations\u001b[38;5;241m.\u001b[39miloc[:, \u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39munique()\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m     13\u001b[0m report \u001b[38;5;241m=\u001b[39m classification_report(all_labels, all_preds, target_names\u001b[38;5;241m=\u001b[39mclass_names, output_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassification Report:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[43mclassification_report\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_preds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_names\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\ilian\\Documents\\Projects\\git_projects\\university\\mushroom_classification\\.venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:216\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    212\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    213\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    214\u001b[0m         )\n\u001b[0;32m    215\u001b[0m     ):\n\u001b[1;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    222\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    224\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    225\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    226\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\ilian\\Documents\\Projects\\git_projects\\university\\mushroom_classification\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:2724\u001b[0m, in \u001b[0;36mclassification_report\u001b[1;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[0;32m   2722\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2723\u001b[0m     longest_last_line_heading \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweighted avg\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 2724\u001b[0m     name_width \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mmax\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcn\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtarget_names\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2725\u001b[0m     width \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(name_width, \u001b[38;5;28mlen\u001b[39m(longest_last_line_heading), digits)\n\u001b[0;32m   2726\u001b[0m     head_fmt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m:>\u001b[39m\u001b[38;5;132;01m{width}\u001b[39;00m\u001b[38;5;124ms} \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{:>9}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(headers)\n",
      "File \u001b[1;32mc:\\Users\\ilian\\Documents\\Projects\\git_projects\\university\\mushroom_classification\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:2724\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   2722\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2723\u001b[0m     longest_last_line_heading \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweighted avg\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 2724\u001b[0m     name_width \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcn\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m cn \u001b[38;5;129;01min\u001b[39;00m target_names)\n\u001b[0;32m   2725\u001b[0m     width \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(name_width, \u001b[38;5;28mlen\u001b[39m(longest_last_line_heading), digits)\n\u001b[0;32m   2726\u001b[0m     head_fmt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m:>\u001b[39m\u001b[38;5;132;01m{width}\u001b[39;00m\u001b[38;5;124ms} \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{:>9}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(headers)\n",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'int' has no len()"
     ]
    }
   ],
   "source": [
    "# Global Evaluation\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for images, labels in DataLoader(val_subset, batch_size=8):\n",
    "        outputs = model(images)\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "class_names = train_dataset.annotations.iloc[:, 1].unique().tolist()\n",
    "report = classification_report(all_labels, all_preds, target_names=class_names, output_dict=True)\n",
    "print(\"Classification Report:\\n\", classification_report(all_labels, all_preds, target_names=class_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=0.001, weight_decay=0.01)\n",
    "scheduler = OneCycleLR(\n",
    "    optimizer,\n",
    "    max_lr=0.001,\n",
    "    total_steps=1000,  # Simulate 1000 training steps\n",
    "    pct_start=0.1,\n",
    "    anneal_strategy='cos',\n",
    "    div_factor=25.0\n",
    ")\n",
    "\n",
    "lrs = []\n",
    "for step in range(1000):\n",
    "    scheduler.step()\n",
    "    lrs.append(optimizer.param_groups[0]['lr'])\n",
    "\n",
    "plt.plot(lrs)\n",
    "plt.title(\"Learning Rate Schedule with Warm-Up\")\n",
    "plt.xlabel(\"Training Step\")\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per-Class Metrics\n",
    "print(\"Per-Class Metrics:\")\n",
    "print(f\"{'Class':<15}{'Precision':<10}{'Recall':<10}{'F1-Score':<10}{'Support':<10}\")\n",
    "print(\"-\" * 55)\n",
    "for class_name, metrics in report.items():\n",
    "    if class_name in class_names:\n",
    "        print(f\"{class_name:<15}{metrics['precision']:<10.2f}{metrics['recall']:<10.2f}{metrics['f1-score']:<10.2f}{metrics['support']:<10}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After collecting predictions and labels from validation or test phase\n",
    "all_preds = torch.cat(all_preds)  \n",
    "all_labels = torch.cat(all_labels) \n",
    "\n",
    "# Compute global confusion matrix\n",
    "cm = confusion_matrix(all_labels.cpu(), all_preds.cpu())\n",
    "\n",
    "# Function to plot confusion matrix per class\n",
    "def plot_per_class_confusion_matrix(cm, class_names):\n",
    "    num_classes = cm.shape[0]\n",
    "    \n",
    "    # Iterate over each class\n",
    "    for i in range(num_classes):\n",
    "        # Extract the row for class `i`\n",
    "        tp = cm[i, i]\n",
    "        fp = cm[:, i].sum() - tp\n",
    "        fn = cm[i, :].sum() - tp\n",
    "        tn = cm.sum() - (tp + fp + fn)\n",
    "\n",
    "        # Print per-class confusion matrix details\n",
    "        print(f\"Confusion Matrix for Class {i} ({class_names[i]}):\")\n",
    "        print(f\"True Positive (TP): {tp}\")\n",
    "        print(f\"False Positive (FP): {fp}\")\n",
    "        print(f\"False Negative (FN): {fn}\")\n",
    "        print(f\"True Negative (TN): {tn}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "        # Plot confusion matrix for class `i`\n",
    "        per_class_cm = np.array([[tp, fp], [fn, tn]])\n",
    "\n",
    "        plt.figure(figsize=(5, 5))\n",
    "        sns.heatmap(per_class_cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"Pred Class\", \"Other Class\"], yticklabels=[\"True Class\", \"Other Class\"])\n",
    "        plt.title(f\"Confusion Matrix for Class {i} ({class_names[i]})\")\n",
    "        plt.xlabel(\"Predicted\")\n",
    "        plt.ylabel(\"True\")\n",
    "        plt.show()\n",
    "\n",
    "# Assuming `class_names` is a list of the class names\n",
    "class_names = [f\"Class {i}\" for i in range(len(torch.unique(all_labels)))]\n",
    "\n",
    "# Plot per-class confusion matrices\n",
    "plot_per_class_confusion_matrix(cm, class_names)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
